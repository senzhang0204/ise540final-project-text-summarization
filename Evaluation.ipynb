{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "011ddb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "import itertools\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.cluster.util import cosine_distance\n",
    "import nltk\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import sumy\n",
    "from rouge import Rouge\n",
    "from readability import Readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b192edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dcf1f41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path='F:/Course/2021 Fall/ISE 540/Project/y_eva' # evaluation directory\n",
    "output_path='F:/Course/2021 Fall/ISE 540/Project/y_eva/eva_result.csv' # export csv result\n",
    "book_list=os.listdir(input_path)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2bac8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eva=pd.DataFrame(columns=['book','Summary_type','rougle_1_r','rougle_1_p','rougle_1_f','rougle_2_r','rougle_2_p','rougle_2_f','rougle_l_r','rougle_l_p','rougle_l_f','cos_sim','f_score','f_ease','f_grade_levels'])\n",
    "done=[]\n",
    "wrong=[]\n",
    "for i in range(0,len(book_list),2):\n",
    "    try:\n",
    "        def read_article(file_name):\n",
    "            file = open(file_name, \"r\", encoding=\"UTF-8\")\n",
    "            filedata = file.readlines()\n",
    "            # print(filedata)\n",
    "\n",
    "            filedata_new = \" \".join(filedata)               # join every elements in the list into a single element\n",
    "            paragraph = filedata_new.replace(\"\\n \\n \", \".\") # replace newlines between paragraphs by periods(there are usually 2 or 3 newlines between paragraphs, so replace by at least 2 newlines)\n",
    "            paragraph = paragraph.split(\".\")                # Split all periods, so we get sentence by sentence\n",
    "            # print(paragraph)\n",
    "\n",
    "            sentences = []\n",
    "            for sentence in paragraph:\n",
    "                sentence = sentence.replace(\"\\n\", \"\") # remove the extra newlines between sentences\n",
    "                # print(sentence)\n",
    "                sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))\n",
    "\n",
    "            sentences = [[string for string in sublist if string] for sublist in sentences] # Remove the empty elements in every sentences if any\n",
    "            sentences = [string for string in sentences if string] # remove empty lists if any\n",
    "            # sentences.pop() # Drop the last two empty elements\n",
    "            end=0\n",
    "            for test in sentences:\n",
    "                if ('***END' in test) or (('END' in test)&('***' in test)):\n",
    "                    break\n",
    "                end=end+1\n",
    "\n",
    "            if end!=len(sentences):\n",
    "                del sentences[end:]\n",
    "\n",
    "            start=0\n",
    "            for test in sentences:\n",
    "                if ('***START' in test )or (('START' in test)&('***' in test)):\n",
    "                    break\n",
    "                start=start+1\n",
    "            if start!=len(sentences): \n",
    "                del sentences[:start+1]\n",
    "\n",
    "            return sentences\n",
    "\n",
    "        book=read_article(input_path+'/'+book_list[i] )  # reading the book from directory\n",
    "        \n",
    "        cur_book=book_list[i]                           # record the book index  \n",
    "        \n",
    "        eva = open(input_path+'/'+book_list[i]+'_eva.txt', \"r\", encoding=\"UTF-8\")    #read corresponding evaluation\n",
    "        eva = eva.readlines()\n",
    "        eva=\" \".join(eva)\n",
    "        eva=eva.replace('\\n','').replace(\"\\'\",\"\").replace('--','. ').replace(' â€” ','. ').replace('.. ','. ')\n",
    "        eva=re.sub('\\s+',' ',eva)\n",
    "\n",
    "        def split(input_book):          # chapterize the book\n",
    "\n",
    "            cnt=0\n",
    "            idx=dict()\n",
    "\n",
    "            for i in input_book:\n",
    "                if ('chapter' in map(str.lower, i[:1])) & (len(i)>=2) :\n",
    "                    idx[tuple(i)]=cnt\n",
    "\n",
    "                elif ('chapitre' in map(str.lower, i[:1])) & (len(i)>=2) :\n",
    "                    idx[tuple(i)]=cnt   \n",
    "\n",
    "                elif ('chap' in map(str.lower, i[:1])):\n",
    "                    idx[tuple(i)]=cnt\n",
    "\n",
    "                elif ('section' in map(str.lower, i[:1])):\n",
    "                    idx[tuple(i)]=cnt    \n",
    "\n",
    "                cnt=cnt+1\n",
    "\n",
    "            page=sorted(idx.values())\n",
    "\n",
    "            chapter=dict()\n",
    "            cnt=0\n",
    "            while cnt <=len(page)-1:\n",
    "\n",
    "                if cnt!=len(page)-1:\n",
    "                    chapter[cnt+1]=input_book[page[cnt]:page[cnt+1]]\n",
    "\n",
    "                else:\n",
    "                    chapter[cnt+1]=input_book[page[cnt]:]\n",
    "                cnt=cnt+1\n",
    "            return chapter\n",
    "\n",
    "        chap=split(book)\n",
    "\n",
    "        if chap =={}: # backup chapterize method if split function fail\n",
    "            point=1\n",
    "            for page in range(300,len(book),300):\n",
    "                if (page+300)>len(book):\n",
    "                    chap[point]=book[page-300:page]\n",
    "                    chap[point+1]=book[page:]\n",
    "                else:\n",
    "                    chap[point]=book[page-300:page]\n",
    "                point=point+1\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "        def chap_string(input_para): # convert chap into string\n",
    "            string=[]\n",
    "            for tok in input_para:\n",
    "                string.append(\" \".join(tok))\n",
    "            string='. '.join(string)\n",
    "            return(string)\n",
    "        \n",
    "        def agg_sum(input_sum): # convert individual output sentences from Sumy into one-paragraph summary\n",
    "            in_sum=[]\n",
    "            for sens in input_sum:\n",
    "                in_sum.append(str(sens))\n",
    "            in_sum=' '.join(in_sum)\n",
    "            return(in_sum)\n",
    "        \n",
    "        def cos_sim(result_sum,evaluation): # calculate cosine similarity\n",
    "            cos_data=[result_sum, evaluation]\n",
    "            vectorizer_c = TfidfVectorizer( )\n",
    "            vector = vectorizer_c.fit_transform(cos_data)\n",
    "\n",
    "            sim_rs=cosine_similarity(vector)[1][0]\n",
    "            return sim_rs\n",
    "\n",
    "\n",
    "        tot_sum=[]\n",
    "        top_1=[]\n",
    "\n",
    "        for i in chap:\n",
    "\n",
    "\n",
    "\n",
    "            chap_sum=[]\n",
    "            for j in chap[i]:\n",
    "                chap_sum.append(\" \".join(j))\n",
    "            chap_sum=' '.join(chap_sum) \n",
    "\n",
    "            data=[chap_sum] #record tf-idf info\n",
    "            vectorizer = TfidfVectorizer( )\n",
    "            vector1 = vectorizer.fit_transform(data)\n",
    "            tf_sum=sum(vector1.toarray()[0]) \n",
    "\n",
    "            tf_len=len(vector1.toarray()[0]) \n",
    "\n",
    "\n",
    "            parser = PlaintextParser.from_string(chap_string(chap[i]),Tokenizer(\"english\"))\n",
    "            summarizer = LexRankSummarizer()\n",
    "            summary = summarizer(parser.document,4)\n",
    "\n",
    "            try:\n",
    "                top_1.append(agg_sum([summary[0]]))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            tot_sum.append(agg_sum(summary))\n",
    "        tot_sum=' '.join(tot_sum)\n",
    "        top_1=' '.join(top_1)\n",
    "\n",
    "\n",
    "        r=Readability(eva)\n",
    "        f = r.flesch()\n",
    "        df= {'book':cur_book,'Summary_type':'Evaluation','rougle_1_r':'NA','rougle_1_p':'NA','rougle_1_f':'NA','rougle_2_r':'NA','rougle_2_p':'NA','rougle_2_f':'NA','rougle_l_r':'NA','rougle_l_p':'NA','rougle_l_f':'NA','cos_sim':'NA','f_score':f.score,'f_ease':f.ease,'f_grade_levels':f.grade_levels}\n",
    "        df_eva=df_eva.append(df, ignore_index = True)\n",
    "        \n",
    "        \n",
    "        # sometimes baseline model might fail to meet the requirement to calculate rouge score or flesh score, when error raise\n",
    "        # NA will be input as that value\n",
    "        \n",
    "        #choose top1 sentence\n",
    "        rouge = Rouge()\n",
    "\n",
    "        try:\n",
    "            res=rouge.get_scores(top_1, eva)[0]\n",
    "            cur_sim=cos_sim(top_1, eva)\n",
    "            r=Readability(top_1)\n",
    "            f = r.flesch()\n",
    "            df= {'book':cur_book,'Summary_type':'Top1_Sent','rougle_1_r':res['rouge-1']['r'],'rougle_1_p':res['rouge-1']['p'],'rougle_1_f':res['rouge-1']['f'],'rougle_2_r':res['rouge-2']['r'],'rougle_2_p':res['rouge-2']['p'],'rougle_2_f':res['rouge-2']['p'],'rougle_l_r':res['rouge-l']['r'],'rougle_l_p':res['rouge-l']['p'],'rougle_l_f':res['rouge-l']['f'],'cos_sim':cur_sim,'f_score':f.score,'f_ease':f.ease,'f_grade_levels':f.grade_levels}\n",
    "            df_eva=df_eva.append(df, ignore_index = True)\n",
    "        except:\n",
    "            res=rouge.get_scores(top_1, eva)[0]    \n",
    "            cur_sim=cos_sim(top_1, eva)\n",
    "\n",
    "\n",
    "            df= {'book':cur_book,'Summary_type':'Top1_Sent','rougle_1_r':res['rouge-1']['r'],'rougle_1_p':res['rouge-1']['p'],'rougle_1_f':res['rouge-1']['f'],'rougle_2_r':res['rouge-2']['r'],'rougle_2_p':res['rouge-2']['p'],'rougle_2_f':res['rouge-2']['p'],'rougle_l_r':res['rouge-l']['r'],'rougle_l_p':res['rouge-l']['p'],'rougle_l_f':res['rouge-l']['f'],'cos_sim':cur_sim,'f_score':'NA','f_ease':'NA','f_grade_levels':'NA'}\n",
    "            df_eva=df_eva.append(df, ignore_index = True)        \n",
    "        \n",
    "        \n",
    "        #choose first 5 sentence\n",
    "        base_nst=[]\n",
    "        for i in chap:\n",
    "            for j in chap[i][:5]:\n",
    "                base_nst.append(agg_sum(j))\n",
    "        base_nst=' '.join(base_nst)\n",
    "        \n",
    "        try:\n",
    "            res=rouge.get_scores(base_nst, eva)[0]\n",
    "            cur_sim=cos_sim(base_nst, eva)\n",
    "            r=Readability(base_nst)\n",
    "            f = r.flesch()\n",
    "            df= {'book':cur_book,'Summary_type':'first_n_sents','rougle_1_r':res['rouge-1']['r'],'rougle_1_p':res['rouge-1']['p'],'rougle_1_f':res['rouge-1']['f'],'rougle_2_r':res['rouge-2']['r'],'rougle_2_p':res['rouge-2']['p'],'rougle_2_f':res['rouge-2']['p'],'rougle_l_r':res['rouge-l']['r'],'rougle_l_p':res['rouge-l']['p'],'rougle_l_f':res['rouge-l']['f'],'cos_sim':cur_sim,'f_score':f.score,'f_ease':f.ease,'f_grade_levels':f.grade_levels}\n",
    "            df_eva=df_eva.append(df, ignore_index = True)\n",
    "        except:\n",
    "\n",
    "            cur_sim=cos_sim(base_nst, eva)\n",
    "            r=Readability(base_nst)\n",
    "            f = r.flesch()\n",
    "            df= {'book':cur_book,'Summary_type':'first_n_sents','rougle_1_r':'NA','rougle_1_p':'NA','rougle_1_f':'NA','rougle_2_r':'NA','rougle_2_p':'NA','rougle_2_f':'NA','rougle_l_r':'NA','rougle_l_p':'NA','rougle_l_f':'NA','cos_sim':cur_sim,'f_score':f.score,'f_ease':f.ease,'f_grade_levels':f.grade_levels}\n",
    "            df_eva=df_eva.append(df, ignore_index = True)\n",
    "\n",
    "        #choose last 5 sentence\n",
    "        base_last=[]\n",
    "        for i in chap:\n",
    "            for j in chap[i][-5:]:\n",
    "                base_last.append(agg_sum(j))\n",
    "        base_last=' '.join(base_last)\n",
    "        \n",
    "        try:\n",
    "            res=rouge.get_scores(base_last, eva)[0]\n",
    "            cur_sim=cos_sim(base_last, eva)\n",
    "            r=Readability(base_last)\n",
    "            f = r.flesch()\n",
    "            df= {'book':cur_book,'Summary_type':'last_n_sents','rougle_1_r':res['rouge-1']['r'],'rougle_1_p':res['rouge-1']['p'],'rougle_1_f':res['rouge-1']['f'],'rougle_2_r':res['rouge-2']['r'],'rougle_2_p':res['rouge-2']['p'],'rougle_2_f':res['rouge-2']['p'],'rougle_l_r':res['rouge-l']['r'],'rougle_l_p':res['rouge-l']['p'],'rougle_l_f':res['rouge-l']['f'],'cos_sim':cur_sim,'f_score':f.score,'f_ease':f.ease,'f_grade_levels':f.grade_levels}\n",
    "            df_eva=df_eva.append(df, ignore_index = True)\n",
    "        except:\n",
    "\n",
    "            cur_sim=cos_sim(base_last, eva)\n",
    "            r=Readability(base_last)\n",
    "            f = r.flesch()\n",
    "            df= {'book':cur_book,'Summary_type':'last_n_sents','rougle_1_r':'NA','rougle_1_p':'NA','rougle_1_f':'NA','rougle_2_r':'NA','rougle_2_p':'NA','rougle_2_f':'NA','rougle_l_r':'NA','rougle_l_p':'NA','rougle_l_f':'NA','cos_sim':cur_sim,'f_score':f.score,'f_ease':f.ease,'f_grade_levels':f.grade_levels}\n",
    "            df_eva=df_eva.append(df, ignore_index = True)\n",
    "\n",
    "        #choose n random sentence\n",
    "        n=3\n",
    "        base_rand=[]\n",
    "\n",
    "        for i in chap:\n",
    "            rand_choice=random.sample(range(0,len(chap[i])),n)\n",
    "            for j in rand_choice:\n",
    "                base_rand.append(agg_sum(chap[i][j]))\n",
    "        base_rand=' '.join(base_rand)\n",
    "        try:\n",
    "            res=rouge.get_scores(base_rand, eva)[0]\n",
    "            cur_sim=cos_sim(base_rand, eva)\n",
    "            r=Readability(base_rand)\n",
    "            f = r.flesch()\n",
    "            df= {'book':cur_book,'Summary_type':'rand_n_sents','rougle_1_r':res['rouge-1']['r'],'rougle_1_p':res['rouge-1']['p'],'rougle_1_f':res['rouge-1']['f'],'rougle_2_r':res['rouge-2']['r'],'rougle_2_p':res['rouge-2']['p'],'rougle_2_f':res['rouge-2']['p'],'rougle_l_r':res['rouge-l']['r'],'rougle_l_p':res['rouge-l']['p'],'rougle_l_f':res['rouge-l']['f'],'cos_sim':cur_sim,'f_score':f.score,'f_ease':f.ease,'f_grade_levels':f.grade_levels}\n",
    "            df_eva=df_eva.append(df, ignore_index = True)\n",
    "        except:\n",
    "\n",
    "            cur_sim=cos_sim(base_rand, eva)\n",
    "            r=Readability(base_rand)\n",
    "            f = r.flesch()\n",
    "            df= {'book':cur_book,'Summary_type':'rand_n_sents','rougle_1_r':'NA','rougle_1_p':'NA','rougle_1_f':'NA','rougle_2_r':'NA','rougle_2_p':'NA','rougle_2_f':'NA','rougle_l_r':'NA','rougle_l_p':'NA','rougle_l_f':'NA','cos_sim':cur_sim,'f_score':f.score,'f_ease':f.ease,'f_grade_levels':f.grade_levels}\n",
    "            df_eva=df_eva.append(df, ignore_index = True)\n",
    "\n",
    "        #choose 3 longest sentence\n",
    "        n=3\n",
    "        base_long=[]\n",
    "\n",
    "        for i in chap:\n",
    "    \n",
    "            sens_long=sorted(chap[i],key=lambda x:-len(x))[:n]\n",
    "            for j in sens_long:\n",
    "                base_long.append(agg_sum(j))\n",
    "\n",
    "\n",
    "\n",
    "        base_long=' '.join(base_long)\n",
    "\n",
    "        try:\n",
    "            res=rouge.get_scores(base_long, eva)[0]\n",
    "            cur_sim=cos_sim(base_long, eva)\n",
    "            r=Readability(base_long)\n",
    "            f = r.flesch()\n",
    "            df= {'book':cur_book,'Summary_type':'longest_n_sents','rougle_1_r':res['rouge-1']['r'],'rougle_1_p':res['rouge-1']['p'],'rougle_1_f':res['rouge-1']['f'],'rougle_2_r':res['rouge-2']['r'],'rougle_2_p':res['rouge-2']['p'],'rougle_2_f':res['rouge-2']['p'],'rougle_l_r':res['rouge-l']['r'],'rougle_l_p':res['rouge-l']['p'],'rougle_l_f':res['rouge-l']['f'],'cos_sim':cur_sim,'f_score':f.score,'f_ease':f.ease,'f_grade_levels':f.grade_levels}\n",
    "            df_eva=df_eva.append(df, ignore_index = True)\n",
    "        except:\n",
    "\n",
    "            cur_sim=cos_sim(base_long, eva)\n",
    "            r=Readability(base_long)\n",
    "            f = r.flesch()\n",
    "            df= {'book':cur_book,'Summary_type':'longest_n_sents','rougle_1_r':'NA','rougle_1_p':'NA','rougle_1_f':'NA','rougle_2_r':'NA','rougle_2_p':'NA','rougle_2_f':'NA','rougle_l_r':'NA','rougle_l_p':'NA','rougle_l_f':'NA','cos_sim':cur_sim,'f_score':f.score,'f_ease':f.ease,'f_grade_levels':f.grade_levels}\n",
    "            df_eva=df_eva.append(df, ignore_index = True)\n",
    "\n",
    "        #choose 10 shorted sentence\n",
    "        n=10\n",
    "        base_short=[]\n",
    "\n",
    "        for i in chap:\n",
    "            longest=1\n",
    "            sens_long=sorted(chap[i],key=lambda x:len(x))[:n]\n",
    "            for j in sens_long:\n",
    "                base_short.append(agg_sum(j))\n",
    "\n",
    "\n",
    "\n",
    "        base_short=' '.join(base_short)\n",
    "\n",
    "        try:\n",
    "            res=rouge.get_scores(base_short, eva)[0]\n",
    "            cur_sim=cos_sim(base_short, eva)\n",
    "            r=Readability(base_short)\n",
    "            f = r.flesch()\n",
    "            df= {'book':cur_book,'Summary_type':'shortest_n_sents','rougle_1_r':res['rouge-1']['r'],'rougle_1_p':res['rouge-1']['p'],'rougle_1_f':res['rouge-1']['f'],'rougle_2_r':res['rouge-2']['r'],'rougle_2_p':res['rouge-2']['p'],'rougle_2_f':res['rouge-2']['p'],'rougle_l_r':res['rouge-l']['r'],'rougle_l_p':res['rouge-l']['p'],'rougle_l_f':res['rouge-l']['f'],'cos_sim':cur_sim,'f_score':f.score,'f_ease':f.ease,'f_grade_levels':f.grade_levels}\n",
    "            df_eva=df_eva.append(df, ignore_index = True)\n",
    "        except:\n",
    "            res=rouge.get_scores(base_short, eva)[0]    \n",
    "            cur_sim=cos_sim(base_short, eva)\n",
    "\n",
    "\n",
    "            df= {'book':cur_book,'Summary_type':'shortest_n_sents','rougle_1_r':res['rouge-1']['r'],'rougle_1_p':res['rouge-1']['p'],'rougle_1_f':res['rouge-1']['f'],'rougle_2_r':res['rouge-2']['r'],'rougle_2_p':res['rouge-2']['p'],'rougle_2_f':res['rouge-2']['p'],'rougle_l_r':res['rouge-l']['r'],'rougle_l_p':res['rouge-l']['p'],'rougle_l_f':res['rouge-l']['f'],'cos_sim':cur_sim,'f_score':'NA','f_ease':'NA','f_grade_levels':'NA'}\n",
    "            df_eva=df_eva.append(df, ignore_index = True)\n",
    "            \n",
    "        #model summary\n",
    "        res=rouge.get_scores(tot_sum, eva)[0]\n",
    "        cur_sim=cos_sim(tot_sum, eva)\n",
    "        r=Readability(tot_sum)\n",
    "        f = r.flesch()\n",
    "        df= {'book':cur_book,'Summary_type':'model_sum','rougle_1_r':res['rouge-1']['r'],'rougle_1_p':res['rouge-1']['p'],'rougle_1_f':res['rouge-1']['f'],'rougle_2_r':res['rouge-2']['r'],'rougle_2_p':res['rouge-2']['p'],'rougle_2_f':res['rouge-2']['p'],'rougle_l_r':res['rouge-l']['r'],'rougle_l_p':res['rouge-l']['p'],'rougle_l_f':res['rouge-l']['f'],'cos_sim':cur_sim,'f_score':f.score,'f_ease':f.ease,'f_grade_levels':f.grade_levels}\n",
    "        df_eva=df_eva.append(df, ignore_index = True)\n",
    "        done.append(cur_book)\n",
    "        df_eva.to_csv(output_path,index=False)\n",
    "        \n",
    "        print(done)\n",
    "    except:\n",
    "        wrong.append(cur_book)\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
